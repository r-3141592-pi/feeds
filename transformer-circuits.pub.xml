<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
 <title>Transformer Circuits</title>
 <description>Unofficial RSS feed for Transformer Circuits Thread (transformer-circuits.pub)</description>
 <link>https://transformer-circuits.pub/</link>
 <lastBuildDate>Wed, 11 Feb 2026 23:40:16 -0000</lastBuildDate>
 <pubDate>Wed, 11 Feb 2026 23:40:16 -0000</pubDate>
 <item>
  <title>Circuits Cross-Post â Activation Oracles We train language models to answer questions about their own activations in natural language.</title>
  <description>November 2025</description>
  <link>https://alignment.anthropic.com/2025/activation-oracles</link>
  <guid>https://alignment.anthropic.com/2025/activation-oracles</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â November 2025 A short update on harm pressure.</title>
  <description>October 2025</description>
  <link>https://transformer-circuits.pub/2025/november-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/november-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Emergent Introspective Awareness in Large Language Models Lindsey, 2025 We find evidence that language models can introspect on their internal states.</title>
  <description>September 2025</description>
  <link>https://transformer-circuits.pub/2025/introspection/index.html</link>
  <guid>https://transformer-circuits.pub/2025/introspection/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â October 2025 Small updates on visual features and dictionary initialization.</title>
  <description>September 2025</description>
  <link>https://transformer-circuits.pub/2025/october-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/october-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>When Models Manipulate Manifolds: The Geometry of a Counting Task Gurnee et al., 2025 We find geometric structure underlying the mechanisms of a fundamental language model behavior.</title>
  <description>September 2025</description>
  <link>https://transformer-circuits.pub/2025/linebreaks/index.html</link>
  <guid>https://transformer-circuits.pub/2025/linebreaks/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â September 2025 A small update on features and in-context learning.</title>
  <description>August 2025</description>
  <link>https://transformer-circuits.pub/2025/september-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/september-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â August 2025 A small update: How does a persona modify the assistantâs response?</title>
  <description>July 2025</description>
  <link>https://transformer-circuits.pub/2025/august-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/august-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>A Toy Model of Mechanistic (Un)Faithfulness When transcoders go awry.</title>
  <description>April 2025</description>
  <link>https://transformer-circuits.pub/2025/faithfulness-toy-model/index.html</link>
  <guid>https://transformer-circuits.pub/2025/faithfulness-toy-model/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Tracing Attention Computation Through Feature Interactions Kamath et al., 2025 We describe and apply a method to explain attention patterns in terms of
                    feature interactions, and integrate this information into attribution graphs.</title>
  <description>April 2025</description>
  <link>https://transformer-circuits.pub/2025/attention-qk/index.html</link>
  <guid>https://transformer-circuits.pub/2025/attention-qk/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>A Toy Model of Interference Weights Unpacking &quot;interference weights&quot; in some more depth.</title>
  <description>April 2025</description>
  <link>https://transformer-circuits.pub/2025/interference-weights/index.html</link>
  <guid>https://transformer-circuits.pub/2025/interference-weights/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Sparse mixtures of linear transforms We investigate sparse mixture of linear transforms (MOLT), a new approach to transcoders.</title>
  <description>April 2025</description>
  <link>https://transformer-circuits.pub/2025/bulk-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/bulk-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â July 2025 A collection of small updates: revisiting A Mathematical Framework and applications of
                    interpretability to biology.</title>
  <description>April 2025</description>
  <link>https://transformer-circuits.pub/2025/july-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/july-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Automated Auditing A note on using agents to perform automated alignment audits, including using interpretability
                    tools.</title>
  <description>April 2025</description>
  <link>https://alignment.anthropic.com/2025/automated-auditing/</link>
  <guid>https://alignment.anthropic.com/2025/automated-auditing/</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â April 2025 A collection of small updates: jailbreaks, dense features, and spinning up on interpretability.</title>
  <description>March 2025</description>
  <link>https://transformer-circuits.pub/2025/april-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/april-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Progress on Attention An update on our progress studying attention.</title>
  <description>March 2025</description>
  <link>https://transformer-circuits.pub/2025/attention-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/attention-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>On the Biology of a Large Language Model Lindsey et al., 2025 We investigate the internal mechanisms used by Claude 3.5 Haiku â Anthropic&#x27;s lightweight
                    production model â in a variety of contexts.</title>
  <description>February 2025</description>
  <link>https://transformer-circuits.pub/2025/attribution-graphs/biology.html</link>
  <guid>https://transformer-circuits.pub/2025/attribution-graphs/biology.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuit Tracing: Revealing Computational Graphs in Language Models Ameisen et al., 2025 We describe an approach to tracing the &quot;step-by-step&quot; computation involved when a model responds
                    to a single prompt.</title>
  <description>February 2025</description>
  <link>https://transformer-circuits.pub/2025/attribution-graphs/methods.html</link>
  <guid>https://transformer-circuits.pub/2025/attribution-graphs/methods.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Insights on Crosscoder Model Diffing A preliminary note on using crosscoders to diff models.</title>
  <description>January 2025</description>
  <link>https://transformer-circuits.pub/2025/crosscoder-diffing-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/crosscoder-diffing-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â January 2025 A collection of small updates: dictionary learning optimization techniques.</title>
  <description>December 2024</description>
  <link>https://transformer-circuits.pub/2025/january-update/index.html</link>
  <guid>https://transformer-circuits.pub/2025/january-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Stage-Wise Model Diffing A preliminary note on model diffing through dictionary fine-tuning.</title>
  <description>October 2024</description>
  <link>https://transformer-circuits.pub/2024/model-diffing/index.html</link>
  <guid>https://transformer-circuits.pub/2024/model-diffing/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Sparse Crosscoders for Cross-Layer Features and Model Diffing A preliminary note on a way to get consistent features across layers, and even models.</title>
  <description>September 2024</description>
  <link>https://transformer-circuits.pub/2024/crosscoders/index.html</link>
  <guid>https://transformer-circuits.pub/2024/crosscoders/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Using Dictionary Learning Features as Classifiers A preliminary note comparing feature-based and raw-activation based harmfulness classifiers.</title>
  <description>September 2024</description>
  <link>https://transformer-circuits.pub/2024/features-as-classifiers/index.html</link>
  <guid>https://transformer-circuits.pub/2024/features-as-classifiers/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â September 2024 A collection of small updates: investigating successor heads, oversampling data in SAEs.</title>
  <description>August 2024</description>
  <link>https://transformer-circuits.pub/2024/september-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/september-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â August 2024 A collection of small updates: interpretability evals, reproducing self-explanation.</title>
  <description>July 2024</description>
  <link>https://transformer-circuits.pub/2024/august-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/august-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â July 2024 A collection of small updates: five hurdles, linear representations, dark matter, pivot tables,
                    feature sensitivity.</title>
  <description>June 2024</description>
  <link>https://transformer-circuits.pub/2024/july-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/july-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â June 2024 A collection of small updates: topk and gated SAE investigation.</title>
  <description>May 2024</description>
  <link>https://transformer-circuits.pub/2024/june-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/june-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet Templeton et al., 2024 Using a sparse autoencoder, we extract a large number of interpretable features from Claude 3
                    Sonnet. Some appear to be safety-relevant.</title>
  <description>April 2024</description>
  <link>https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html</link>
  <guid>https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â April 2024 A collection of small updates from the Anthropic Interpretability Team.</title>
  <description>March 2024</description>
  <link>https://transformer-circuits.pub/2024/april-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/april-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â March 2024 A collection of small updates from the Anthropic Interpretability Team.</title>
  <description>February 2024</description>
  <link>https://transformer-circuits.pub/2024/march-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/march-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Reflections on Qualitative Research Some opinionated thoughts on why interpretability research may have
                    qualitative aspects be more central than we&#x27;re used to in other fields.</title>
  <description>February 2024</description>
  <link>https://transformer-circuits.pub/2024/qualitative-essay/index.html</link>
  <guid>https://transformer-circuits.pub/2024/qualitative-essay/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â February 2024 A collection of small updates from the Anthropic Interpretability Team.</title>
  <description>January 2024</description>
  <link>https://transformer-circuits.pub/2024/feb-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/feb-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â January 2024 A collection of small updates from the Anthropic Interpretability Team.</title>
  <description>October 2023</description>
  <link>https://transformer-circuits.pub/2024/jan-update/index.html</link>
  <guid>https://transformer-circuits.pub/2024/jan-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Towards Monosemanticity: Decomposing Language Models With Dictionary Learning Bricken et al., 2023 Using a sparse autoencoder, we extract a large number of interpretable features from a one-layer
                    transformer.</title>
  <description>July 2023</description>
  <link>https://transformer-circuits.pub/2023/monosemantic-features/index.html</link>
  <guid>https://transformer-circuits.pub/2023/monosemantic-features/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â July 2023 A collection of small updates from the Anthropic Interpretability Team.</title>
  <description>May 2023</description>
  <link>https://transformer-circuits.pub/2023/july-update/index.html</link>
  <guid>https://transformer-circuits.pub/2023/july-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Circuits Updates â May 2023 A collection of small updates from the Anthropic Interpretability Team.</title>
  <description>March 2023</description>
  <link>https://transformer-circuits.pub/2023/may-update/index.html</link>
  <guid>https://transformer-circuits.pub/2023/may-update/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Interpretability Dreams Our present research aims to create a foundation for mechanistic
                    interpretability research. In doing so, it&#x27;s important to keep sight of what we&#x27;re trying to lay
                    the foundations for.</title>
  <description>March 2023</description>
  <link>https://transformer-circuits.pub/2023/interpretability-dreams/index.html</link>
  <guid>https://transformer-circuits.pub/2023/interpretability-dreams/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Distributed Representations: Composition &amp; Superposition An informal note on how &quot;distributed representations&quot; might be understood
                    as two different, competing strategies â &quot;composition&quot; and &quot;superposition&quot; â with quite
                    different properties.</title>
  <description>March 2023</description>
  <link>https://transformer-circuits.pub/2023/superposition-composition/index.html</link>
  <guid>https://transformer-circuits.pub/2023/superposition-composition/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Privileged Bases in the Transformer Residual Stream Our mathematical theories of the Transformer architecture suggest that
                    individual coordinates in the residual stream should have no special
                    significance, but recent work has shown that this observation is false in practice.
                    We investigate this phenomenon and provisionally conclude that the per-dimension normalizers in
                    the Adam optimizer are to blame for the effect.</title>
  <description>January 2023</description>
  <link>https://transformer-circuits.pub/2023/privileged-basis/index.html</link>
  <guid>https://transformer-circuits.pub/2023/privileged-basis/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Superposition, Memorization, and Double Descent Henighan et al., 2023 We have little mechanistic understanding of how deep learning
                    models overfit to their training data, despite it being a
                    central problem. Here we extend our previous work on toy models
                    to shed light on how models generalize beyond their training
                    data.</title>
  <description>September 2022</description>
  <link>https://transformer-circuits.pub/2023/toy-double-descent/index.html</link>
  <guid>https://transformer-circuits.pub/2023/toy-double-descent/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Toy Models of Superposition Elhage et al., 2022 Neural networks often seem to pack many unrelated concepts into a single
                    neuron - a puzzling phenomenon known as &#x27;polysemanticity&#x27;. In our latest interpretability work,
                    we build toy models where the origins and dynamics of polysemanticity can be fully understood.</title>
  <description>June 2022</description>
  <link>https://transformer-circuits.pub/2022/toy_model/index.html</link>
  <guid>https://transformer-circuits.pub/2022/toy_model/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Softmax Linear Units An alternative activation function increases the fraction of neurons which
                    appear to correspond to human-understandable concepts.</title>
  <description>March 2022</description>
  <link>https://transformer-circuits.pub/2022/solu/index.html</link>
  <guid>https://transformer-circuits.pub/2022/solu/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Mechanistic Interpretability, Variables, and the Importance of Interpretable Bases An informal note on intuitions related to mechanistic interpretability.</title>
  <description>March 2022</description>
  <link>https://transformer-circuits.pub/2022/mech-interp-essay/index.html</link>
  <guid>https://transformer-circuits.pub/2022/mech-interp-essay/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>In-Context Learning and Induction Heads Olsson et al., 2022 An exploration of the hypothesis that induction heads are the primary
                    mechanism behind in-context learning. We also report the existence of a previously unknown phase
                    change in transformers language models. paper</title>
  <description>December 2021</description>
  <link>https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html</link>
  <guid>https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>A Mathematical Framework for Transformer Circuits Elhage et al., 2021 Our early mathematical framework for reverse engineering models,
                    demonstrated by reverse engineering small toy models. paper</title>
  <description>March 2020 - April 2021</description>
  <link>https://transformer-circuits.pub/2021/framework/index.html</link>
  <guid>https://transformer-circuits.pub/2021/framework/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Exercises Some exercises we&#x27;ve developed to improve our understanding of how neural
                    networks implement algorithms at the parameter level. note, exercises</title>
  <description>March 2020 - April 2021</description>
  <link>https://transformer-circuits.pub/2021/exercises/index.html</link>
  <guid>https://transformer-circuits.pub/2021/exercises/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Videos Very rough informal talks as we search for a way to reverse engineering
                    transformers. links, videos</title>
  <description>March 2020 - April 2021</description>
  <link>https://transformer-circuits.pub/2021/videos/index.html</link>
  <guid>https://transformer-circuits.pub/2021/videos/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Garcon A description of our tooling for doing interpretability on large models. note, infrastructure</title>
  <description>March 2020 - April 2021</description>
  <link>https://transformer-circuits.pub/2021/garcon/index.html</link>
  <guid>https://transformer-circuits.pub/2021/garcon/index.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Original Distill Circuits Thread Our exploration of Transformers builds heavily on the original Circuits
                    thread on Distill.</title>
  <description>December 2025 Circuits Cross-Post â Activation Oracles We train language models to answer questions about their own activations in natural language. November 2025 Circuits Updates â November 2025 A short update on harm pressure. October 2025 Emergent Introspective Awareness in Large Language Models Lindsey, 2025 We find evidence that language models can introspect on their internal states. Circuits Updates â October 2025 Small updates on visual features and dictionary initialization. When Models Manipulate Manifolds: The Geometry of a Counting Task Gurnee et al., 2025 We find geometric structure underlying the mechanisms of a fundamental language model behavior. September 2025 Circuits Updates â September 2025 A small update on features and in-context learning. August 2025 Circuits Updates â August 2025 A small update: How does a persona modify the assistantâs response? July 2025 A Toy Model of Mechanistic (Un)Faithfulness When transcoders go awry. Tracing Attention Computation Through Feature Interactions Kamath et al., 2025 We describe and apply a method to explain attention patterns in terms of
                    feature interactions, and integrate this information into attribution graphs. A Toy Model of Interference Weights Unpacking &quot;interference weights&quot; in some more depth. Sparse mixtures of linear transforms We investigate sparse mixture of linear transforms (MOLT), a new approach to transcoders. Circuits Updates â July 2025 A collection of small updates: revisiting A Mathematical Framework and applications of
                    interpretability to biology. Automated Auditing A note on using agents to perform automated alignment audits, including using interpretability
                    tools. April 2025 Circuits Updates â April 2025 A collection of small updates: jailbreaks, dense features, and spinning up on interpretability. Progress on Attention An update on our progress studying attention. March 2025 On the Biology of a Large Language Model Lindsey et al., 2025 We investigate the internal mechanisms used by Claude 3.5 Haiku â Anthropic&#x27;s lightweight
                    production model â in a variety of contexts. Circuit Tracing: Revealing Computational Graphs in Language Models Ameisen et al., 2025 We describe an approach to tracing the &quot;step-by-step&quot; computation involved when a model responds
                    to a single prompt. February 2025 Insights on Crosscoder Model Diffing A preliminary note on using crosscoders to diff models. January 2025 Circuits Updates â January 2025 A collection of small updates: dictionary learning optimization techniques. December 2024 Stage-Wise Model Diffing A preliminary note on model diffing through dictionary fine-tuning. October 2024 Sparse Crosscoders for Cross-Layer Features and Model Diffing A preliminary note on a way to get consistent features across layers, and even models. Using Dictionary Learning Features as Classifiers A preliminary note comparing feature-based and raw-activation based harmfulness classifiers. September 2024 Circuits Updates â September 2024 A collection of small updates: investigating successor heads, oversampling data in SAEs. August 2024 Circuits Updates â August 2024 A collection of small updates: interpretability evals, reproducing self-explanation. July 2024 Circuits Updates â July 2024 A collection of small updates: five hurdles, linear representations, dark matter, pivot tables,
                    feature sensitivity. June 2024 Circuits Updates â June 2024 A collection of small updates: topk and gated SAE investigation. May 2024 Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet Templeton et al., 2024 Using a sparse autoencoder, we extract a large number of interpretable features from Claude 3
                    Sonnet. Some appear to be safety-relevant. April 2024 Circuits Updates â April 2024 A collection of small updates from the Anthropic Interpretability Team. March 2024 Circuits Updates â March 2024 A collection of small updates from the Anthropic Interpretability Team. Reflections on Qualitative Research Some opinionated thoughts on why interpretability research may have
                    qualitative aspects be more central than we&#x27;re used to in other fields. February 2024 Circuits Updates â February 2024 A collection of small updates from the Anthropic Interpretability Team. January 2024 Circuits Updates â January 2024 A collection of small updates from the Anthropic Interpretability Team. October 2023 Towards Monosemanticity: Decomposing Language Models With Dictionary Learning Bricken et al., 2023 Using a sparse autoencoder, we extract a large number of interpretable features from a one-layer
                    transformer. July 2023 Circuits Updates â July 2023 A collection of small updates from the Anthropic Interpretability Team. May 2023 Circuits Updates â May 2023 A collection of small updates from the Anthropic Interpretability Team. Interpretability Dreams Our present research aims to create a foundation for mechanistic
                    interpretability research. In doing so, it&#x27;s important to keep sight of what we&#x27;re trying to lay
                    the foundations for. Distributed Representations: Composition &amp; Superposition An informal note on how &quot;distributed representations&quot; might be understood
                    as two different, competing strategies â &quot;composition&quot; and &quot;superposition&quot; â with quite
                    different properties. March 2023 Privileged Bases in the Transformer Residual Stream Our mathematical theories of the Transformer architecture suggest that
                    individual coordinates in the residual stream should have no special
                    significance, but recent work has shown that this observation is false in practice.
                    We investigate this phenomenon and provisionally conclude that the per-dimension normalizers in
                    the Adam optimizer are to blame for the effect. January 2023 Superposition, Memorization, and Double Descent Henighan et al., 2023 We have little mechanistic understanding of how deep learning
                    models overfit to their training data, despite it being a
                    central problem. Here we extend our previous work on toy models
                    to shed light on how models generalize beyond their training
                    data. September 2022 Toy Models of Superposition Elhage et al., 2022 Neural networks often seem to pack many unrelated concepts into a single
                    neuron - a puzzling phenomenon known as &#x27;polysemanticity&#x27;. In our latest interpretability work,
                    we build toy models where the origins and dynamics of polysemanticity can be fully understood. June 2022 Softmax Linear Units An alternative activation function increases the fraction of neurons which
                    appear to correspond to human-understandable concepts. Mechanistic Interpretability, Variables, and the Importance of Interpretable Bases An informal note on intuitions related to mechanistic interpretability. March 2022 In-Context Learning and Induction Heads Olsson et al., 2022 An exploration of the hypothesis that induction heads are the primary
                    mechanism behind in-context learning. We also report the existence of a previously unknown phase
                    change in transformers language models. paper December 2021 A Mathematical Framework for Transformer Circuits Elhage et al., 2021 Our early mathematical framework for reverse engineering models,
                    demonstrated by reverse engineering small toy models. paper Exercises Some exercises we&#x27;ve developed to improve our understanding of how neural
                    networks implement algorithms at the parameter level. note, exercises Videos Very rough informal talks as we search for a way to reverse engineering
                    transformers. links, videos PySvelte One approach to bridging Python and web-based interactive diagrams for
                    interpretability research. github link, infrastructure Garcon A description of our tooling for doing interpretability on large models. note, infrastructure March 2020 - April 2021</description>
  <link>https://distill.pub/2020/circuits/</link>
  <guid>https://distill.pub/2020/circuits/</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 -0000</pubDate>
 </item> <item>
  <title>Activation Atlases</title>
  <description>We think interpretability research benefits a lot from interactive articles (see  for a striking
                example).
                Previously we would have submitted to Distill, but with Distill on Hiatus ,
                we&#x27;re taking a page from David Haâs approach of simply creating websites (eg. World Models ) for research projects.</description>
  <link>https://distill.pub/2019/activation-atlas/</link>
  <guid>https://distill.pub/2019/activation-atlas/</guid>
  <pubDate>Wed, 11 Feb 2026 23:40:16 -0000</pubDate>
 </item> <item>
  <title>Distill on Hiatus</title>
  <description>We think interpretability research benefits a lot from interactive articles (see Activation Atlases for a striking
                example).
                Previously we would have submitted to Distill, but with  ,
                we&#x27;re taking a page from David Haâs approach of simply creating websites (eg. World Models ) for research projects.</description>
  <link>https://distill.pub/2021/distill-hiatus/</link>
  <guid>https://distill.pub/2021/distill-hiatus/</guid>
  <pubDate>Wed, 11 Feb 2026 23:40:16 -0000</pubDate>
 </item>
</channel>
</rss>